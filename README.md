NYC Taxi Data Analytics & Engineering Platform
A robust batch data pipeline project using PySpark and Databricks, built as part of a Data Engineering Technical Assessment. This project processes NYC TLC Yellow & Green taxi trip data to power analytics through a dimensional model, performance-optimized Spark jobs, and insightful SQL queries.

ğŸ§­ Project Summary
 Built a modular ETL pipeline with PySpark on Databricks

 Processed 3 months of NYC Yellow & Green taxi trip data

 Designed a Star Schema for analytical workloads

 Applied data quality rules, outlier filtering, and aggregations

 Created reusable analysis queries to uncover revenue patterns and ride behaviors

ğŸ—ï¸ Architecture & Data Flow
Ingest raw CSV files â†’ transform with PySpark â†’ write Delta tables

Star Schema model supports fast querying and reporting

Stored curated data in Azure Data Lake

Partitioned by time/location for optimization

Prepared for future enhancements like streaming ingestion

 Architecture Diagram

ğŸ§  Data Modeling Highlights
Component	Description
âœ… fact_trips	Trip-level fact table with cleaned and enriched data
âœ… Dimensions	Zones, Rate Codes, Payment Types
ğŸ“¦ SCD Types	Type 2 for Zones & Payment Types, Type 1 for Rate Codes
ğŸ“Š Aggregations	Revenue trends, long trips, weekday/weekend patterns

ğŸ“„ View Model Design

ğŸ” ETL Logic (PySpark)
Implemented in combined_taxi.ipynb:

ğŸ§® Trip duration & average speed computation

ğŸš« Outlier detection (e.g., 0 fare, abnormal durations)

ğŸ”— Zone enrichment via joins

ğŸ“† Time-based partitioning (hour/day/month)

ğŸ“Š Aggregation tables for revenue and trip analysis

âœ… Data validation and quality enforcement

ğŸ“Š Analysis & Business Queries
ğŸ’° Top 10 Pickup Zones by Revenue
queries/top_10_pickups.sql

ğŸ“… Trip Patterns: Weekday vs Weekend
queries/weekday_weekend_patterns.sql

ğŸ›£ï¸ Top 10 Longest Trips (>10 miles)
queries/top_10_long_trips.sql

ğŸš€ Performance & Optimization
âš¡ Broadcast joins for small lookup tables

ğŸ§Š Delta Lake + predicate pushdown

ğŸ§± Partitioning by pickup datetime and zone

ğŸ§® Pre-aggregated summary tables for BI tools

ğŸ” Indexed keys and compacted tables for efficiency

ğŸ—‚ï¸ Folder Structure
bash
Copy
Edit
nyc-taxi-data-platform/
â”œâ”€â”€ notebooks/              # PySpark ETL scripts
â”œâ”€â”€ docs/                   # Architecture and model docs
â”œâ”€â”€ queries/                # SQL analysis queries
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
ğŸ› ï¸ Tech Stack
ğŸ PySpark & Spark SQL

ğŸ”¥ Databricks (Spark runtime on Azure)

ğŸŒŠ Azure Data Lake + Delta Lake

ğŸ§± Star Schema, SCD Type 1 & 2

ğŸ—ƒï¸ SQL for analytical querying

â–¶ï¸ How to Run
Upload the notebook to your Databricks workspace

Attach to a Spark 3.x-compatible cluster

Add NYC TLC Yellow & Green taxi CSVs (3 months)

Run all cells to generate fact/dimension/aggregate tables

Use SQL queries or views for analytics

ğŸ“ Key Resources
ğŸ“ docs/dimensional_model.md: Data warehouse schema

ğŸ“Š notebooks/combined_taxi.ipynb: Full ETL & pipeline logic

ğŸ“ˆ queries/: SQL queries for 2024 analytics

ğŸ“„ License
MIT License â€“ use freely for learning, interview prep, or extending your own data engineering workflows.

